# 1. nvidia-smi显示显存充足



# 2. PyTorch OOM message

PyTorch的OOM message

```
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.64 GiB (GPU 0; 11.77 GiB total capacity; 6.06 GiB already allocated; 1.78 GiB free; 8.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CON
```



```
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 26.38 GiB. GPU 0 has a total capacty of 44.55 GiB of which 10.85 GiB is free. Process 314188 has 18.94 GiB memory in use. Including non-PyTorch memory, this process has 14.74 GiB memory in use. Of the allocated memory 14.27 GiB is allocated by PyTorch, and 48.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
```

