# LLM/VLM压缩与推理加速

一些LLM/VLM压缩与推理加速的技术与项目：

1. vLLM
2. Mooncake
3. Attentionstore
4. GraphRAG
5. MSRA Ladder与T-MAC
6. llamacpp





LLM中的scaling law



Langchain

llamaindex



scale-out与scale-up



LLM API **output token**与**input token**





# FlashAttention

<img src="assets/image-20240831100909652.png" alt="image-20240831100909652" style="zoom:67%;" />

