# MuLi在交大的讲座记录



**在硬件方面**，分布式训练中，最重要的是带宽。

多卡最开始是分散在多台机器上，现在的趋势是尽量将多卡放在一台机器上，降低多机之间的通讯延迟。

散热也趋向于风冷转为水冷，从而能够在单台机器上塞下更多的GPU。



带宽之后就是内存。内存大小决定了模型的大小，内存在未来几年可能成为瓶颈。

近些年的HBM技术。



近几年NVIDIA通过低精度浮点数(FP4，FP8 E4M3，E5M2)来提升GPU的吞吐。

算力的提升伴随而来的是对于电力需求的提升。

目前在训练芯片方面并没有NVIDIA的替代品，推理芯片比如Intel和AMD有相应推理芯片。



**在模型方面**

目前的LLM：

- 预训练token 10-50T
- 100-500B参数量(MoE可能更多)
- Omni模型？



不同模态：

- Image与language 非常成熟
- Video 还不是很成熟
- MultiModal是目前的趋势，语言信息含量高并且容易获取，利用模型从语言方面的能力泛化到其它模块。并且文本能够训练定制化模型，能够控制模型行为。



语言模型的发展同时也带来了人机交互方面的改变。

但是目前还没有一个对应的killer app。



**在应用方面**

AI在处理blue collar的任务方面非常弱。因为blue collar的任务场景多变，很难采集到足够的数据。而AI就是需要足够的数据。

只要一个行业能够采集到足够多的数据，才能够使用AI将其自动化。AI 理解蓝领的世界，包括和这个世界互动可能需要至少 5 年时间。





预训练是工程问题，后训练是技术问题(但是几年前预训练是技术问题)。

对于后训练，高质量的数据和改进的算法能够极大地提升模型效果。预训练的数据是把整个互联网的数据拿来训练，而后训练数据是结构化的，并且与应用场景高度相关。



垂直模型。并没有真正的垂直模型，垂直模型的通用能力不能差。



模型评估很难但是也很重要。



数据决定模型上限而算法决定模型下限。就目前来说，我们离 AGI 还很远， AGI 能够做自主的学习，我们目前的模型就是填鸭式状态。



自建集群和租云服务器成本差不多，在存储与带宽方面能够省很多。



现在的LLM和过去并没有很大区别，还是吃数据，评估还是很重要，所以很多之前的经验还是能用过来，可以参考借鉴。

LLM的困难在于它的大，而带来很多工程方面的问题，算法探索不够。

